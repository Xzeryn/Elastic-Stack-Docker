
volumes:
  mldata01:
    driver: local
  fzdata01:
    driver: local
  minio-data:
    driver: local
  metricbeatdata01:
    driver: local
  filebeatdata01:
    driver: local
  logstashdata01:
    driver: local

services:
  # The ml01 is configured to be a dedicated ML node within the cluster large enough to download and install the ELSER model
  ml01:
    extends:
      file: elastic-stack.yml
      service: elasticsearch
    profiles:
      - ml
    depends_on:
      es01:
        condition: service_healthy
    volumes:
      - mldata01:/usr/share/elasticsearch/data
    environment:
      - node.name=ml01
      - node.roles=ml, remote_cluster_client
      - discovery.seed_hosts=es01
      - xpack.security.http.ssl.key=certs/ml01/ml01.key
      - xpack.security.http.ssl.certificate=certs/ml01/ml01.crt
      - xpack.security.transport.ssl.key=certs/ml01/ml01.key
      - xpack.security.transport.ssl.certificate=certs/ml01/ml01.crt
    deploy:
      resources:
        limits:
          cpus: ${ML_CPU_LIMIT}
          memory: ${ML_MEM_LIMIT}
        reservations:
          cpus: ${ML_CPU_LIMIT}
          memory: ${ML_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1

  # The fz01 is configured to be a dedicated Frozen node within the cluster
  fz01:
    extends:
      file: elastic-stack.yml
      service: elasticsearch
    profiles:
      - frozen
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - fzdata01:/usr/share/elasticsearch/data
      - ./config/es-frozen_node-startup.sh:/usr/local/bin/es-frozen_node-startup.sh:ro
    entrypoint: ["es-frozen_node-startup.sh"]
    environment:
      - node.name=fz01
      - node.roles=data_frozen
      - discovery.seed_hosts=es01
      - xpack.security.http.ssl.key=certs/fz01/fz01.key
      - xpack.security.http.ssl.certificate=certs/fz01/fz01.crt
      - xpack.security.transport.ssl.key=certs/fz01/fz01.key
      - xpack.security.transport.ssl.certificate=certs/fz01/fz01.crt
      - xpack.searchable.snapshot.shared_cache.size=${SNAPSHOT_SHARED_CACHE_SIZE}
    deploy:
      resources:
        limits:
          cpus: ${FROZEN_CPU_LIMIT}
          memory: ${FROZEN_MEM_LIMIT}
        reservations:
          cpus: ${FROZEN_CPU_LIMIT}
          memory: ${FROZEN_MEM_LIMIT}

  # The minio service is used to store the frozen snapshots. It is configured to be a standalone service
  minio:
    image: minio/minio:latest
    container_name: minio
    profiles:
      - frozen
    ports:
      - ${MINIO_API_PORT}:9000
      - ${MINIO_GUI_PORT}:9001
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -f http://localhost:9000/minio/health/live",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # The minio-setup service is used to configure the minio service.
  minio-setup:
    image: minio/mc:latest
    container_name: minio-setup
    profiles:
      - frozen
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MC_HOSTS: minio=http://minio:9000
      MC_ALIAS: minio
      MINIO_BUCKET_NAME: ${MINIO_BUCKET_NAME}
    entrypoint: >
      sh -c "
        sleep 5;
        mc alias set es-s3 http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
        mc mb es-s3/${MINIO_BUCKET_NAME};
        echo '
        {
          \"Version\": \"2012-10-17\",
          \"Statement\": [
            {
              \"Effect\": \"Allow\",
              \"Action\": [
                  \"s3:ListBucket\"
              ],
              \"Resource\": [
                  \"arn:aws:s3:::'${MINIO_BUCKET_NAME}'\"
              ]
            },
            {
              \"Effect\": \"Allow\",
              \"Action\": [
                  \"s3:*Object\"
              ],
              \"Resource\": [
                  \"arn:aws:s3:::'${MINIO_BUCKET_NAME}'/*\"
              ]
            }
          ]
        }' > /tmp/elastic-bucket-policy.json;
        mc admin policy create es-s3 elastic-s3 /tmp/elastic-bucket-policy.json;
        mc admin user add es-s3 ${MINIO_ACCESS_KEY} ${MINIO_SECRET_KEY};
        mc admin policy attach es-s3 readwrite --user ${MINIO_ACCESS_KEY};
        mc admin policy attach es-s3 elastic-s3 --user ${MINIO_ACCESS_KEY};
        mc ls es-s3;
        echo 'MinIO operations completed.';
        # while true; do sleep 30; done;
      "

  # Metricbeat is used for stack monitoring (Optional)
  metricbeat01:
    profiles:
      - monitoring
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: docker.elastic.co/beats/metricbeat:${STACK_VERSION}
    restart: unless-stopped
    user: root
    volumes:
      - certs:/usr/share/metricbeat/certs
      - metricbeatdata01:/usr/share/metricbeat/data
      - "./config/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01:9200,https://es02:9200,https://es03:9200
      - KIBANA_HOSTS=https://kibana:5601
      - LOGSTASH_HOSTS=http://logstash01:9600
      - CA_CERT=certs/ca/ca.crt
      - ES_CERT=certs/es01/es01.crt
      - ES_KEY=certs/es01/es01.key
      - KB_CERT=certs/kibana/kibana.crt
      - KB_KEY=certs/kibana/kibana.key
    command:
      -strict.perms=false
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert /usr/share/metricbeat/certs/ca/ca.crt https://es01:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # Filebeat is configured to ingest data from the filebeat_ingest_data folder, drop .log files in this folder to ingest
  # Filebeat is also configured to pull logs for all docker containers (visible in the Logs Stream viewer) (Optional)
  filebeat01:
    profiles:
      - filebeat
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: docker.elastic.co/beats/filebeat:${STACK_VERSION}
    restart: unless-stopped
    user: root
    volumes:
      - certs:/usr/share/filebeat/certs
      - filebeatdata01:/usr/share/filebeat/data
      - "./filebeat_ingest_data/:/usr/share/filebeat/ingest_data/"
      - "./config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro"
      - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01:9200
      - KIBANA_HOSTS=https://kibana:5601
      - LOGSTASH_HOSTS=http://logstash01:9600
      - CA_CERT=certs/ca/ca.crt
    command:
      -strict.perms=false
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert /usr/share/filebeat/certs/ca/ca.crt https://es01:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # Logstash is configured to ingest data from the logstash_ingest_data folder (Optional)
  logstash01:
    profiles:
      - logstash
    depends_on:
      es01:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
    restart: unless-stopped
    labels:
      co.elastic.logs/module: logstash
    volumes:
      - certs:/usr/share/logstash/certs
      - logstashdata01:/usr/share/logstash/data
      - "./logstash_ingest_data/:/usr/share/logstash/ingest_data/"
      - "./config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro"
    environment:
      - xpack.monitoring.enabled=false
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://es01:9200
    deploy:
      resources:
        limits:
          cpus: ${LOGSTASH_CPU_LIMIT}
          memory: ${LOGSTASH_MEM_LIMIT}
        reservations:
          cpus: ${LOGSTASH_CPU_LIMIT}
          memory: ${LOGSTASH_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert /usr/share/logstash/certs/ca/ca.crt https://es01:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # The webapp is an example insturmentation of the elastic APM agent. (Optional)
  # Access the webapp through http://localhost:8000
  webapp:
    profiles:
      - apm
    image: webapp:${STACK_VERSION}
    build:
      context: app
    restart: unless-stopped
    volumes:
      - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    ports:
      - ${APM_APP_PORT}:8000
    healthcheck:
      test:
        [ 
          "CMD-SHELL", 
          "curl -s http://localhost:8000",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # The container-agent is an example of insturmenting an agent within a docker container
  container-agent:
    extends:
      file: elastic-stack.yml
      service: elastic-agent
    profiles:
      - agent
    depends_on:
      fleet-server:
        condition: service_healthy
    hostname: container-agent
    volumes:
      - "./agent_ingest_data:/tmp/ingest_data"
      # The following line is not required, nor is the `entrypoint` line. They are running a script to add 
      # integrations to the Fleet policy this agent connects to for demo functionality
      - ./config/agent_add_integrations-startup.sh:/usr/share/elastic-agent/agent-startup.sh
    entrypoint: ["agent-startup.sh"]
    ports:
      - ${AGENT_SYSLOG_UDP_PORT}:9003
      - ${AGENT_SYSLOG_TCP_PORT}:9004
    environment:
      - FLEET_TOKEN_POLICY_NAME=Docker-Container-Policy
      - INTEGRATION_FILESTREAM_VERSION=${INTEGRATION_FILESTREAM_VERSION}
      - INTEGRATION_TCP_LOGS_VERSION=${INTEGRATION_TCP_LOGS_VERSION}
      - INTEGRATION_UDP_LOGS_VERSION=${INTEGRATION_UDP_LOGS_VERSION}

  # Tthe Elastic MCP Server allows LLM Clients to communicate with the Elastic cluster using streamable-HTTP protocol
  mcp-server:
    image: docker.elastic.co/mcp/elasticsearch:latest
    profiles:
      - mcp
    depends_on:
      es01:
        condition: service_healthy
    hostname: es-mcp-server
    command: http
    ports:
      - ${MCP_HTTP_PORT}:8080
    environment:
      - ES_URL=https://es01:9200
      - ES_USERNAME=elastic
      - ES_PASSWORD=${ELASTIC_PASSWORD}
      - ES_SSL_SKIP_VERIFY=true